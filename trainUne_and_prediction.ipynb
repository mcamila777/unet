{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## container\n",
    "container-test-beds/ml_keras_tf/ml_keras_tf.sif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "os.chdir('../Board_AI')\n",
    "\n",
    "import boardai.config.config_board_AI as config\n",
    "import boardai.nn.nn_utils as nn_utils\n",
    "\n",
    "\n",
    "os.chdir('../unet')\n",
    "\n",
    "\n",
    "from model import *\n",
    "from data import *\n",
    "\n",
    "import keras\n",
    "\n",
    "import matplotlib, matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "from skimage import exposure\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split_path = os.path.join(config.DATA_DIR_GENERAL, \"segmentation_split\")\n",
    "\n",
    "train_dir =  os.path.join(data_split_path,  \"train\")\n",
    "test_dir =  os.path.join(data_split_path,  \"test\")\n",
    "\n",
    "\n",
    "img_folder = \"imgs\"\n",
    "label_folder = \"label\"\n",
    "\n",
    "train_files = glob.glob(train_dir + \"/\" + img_folder + \"/*.png\")\n",
    "test_files = glob.glob(test_dir + \"/\" + img_folder + \"/*.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# print(tf.__version__)\n",
    "\n",
    "# print(\"\\nis_gpu_available: \", tf.test.is_gpu_available(\n",
    "#     cuda_only=False,\n",
    "#     min_cuda_compute_capability=None))\n",
    "\n",
    "# from tensorflow.python.client import device_lib\n",
    "# print(\"\\n\",device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your Unet with membrane data\n",
    "membrane data is in folder membrane/, it is a binary classification task.\n",
    "\n",
    "The input shape of image and mask are the same :(batch_size,rows,cols,channel = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = \"grayscale\",\n",
    "#                     mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
    "#                     flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (256,256),seed = 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "# myGene = trainGenerator(3,'data/membrane/train','image','label',data_gen_args,save_to_dir = None)\n",
    "train_gen = trainGenerator(batch_size, train_dir,img_folder,label_folder,\n",
    "                        data_gen_args,save_to_dir = None)\n",
    "test_gen = trainGenerator(batch_size, test_dir,img_folder,label_folder,\n",
    "                        data_gen_args,save_to_dir = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img , mask = next(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(img[0,:,:,0] , cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(mask[0,:,:,0] , cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(mask))\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_id = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "model_path = \"./logs/\" + model_id\n",
    "\n",
    "os.mkdir(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = unet()\n",
    "metrics = []\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_gen,\n",
    "    validation_steps=len(test_files) // batch_size,\n",
    "    validation_data= test_gen, #(X_val, y_val),\n",
    "    steps_per_epoch=2000 ,#len(train_files)// batch_size, # 2000,  # amount_training_samples // batch_size,\n",
    "    epochs=5,#50,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            model_path + \"/model.{epoch:02d}-{val_loss:.4f}.h5\",\n",
    "            save_best_only=True,\n",
    "        ),\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor= \"val_loss\",\n",
    "            patience=30,\n",
    "        ),\n",
    "        keras.callbacks.TensorBoard(\n",
    "            log_dir=model_path,\n",
    "            histogram_freq=0,\n",
    "            write_graph=False,\n",
    "            write_images=False,\n",
    "        ),\n",
    "#         keras.callbacks.ReduceLROnPlateau(\n",
    "#             monitor=7,\n",
    "#             factor=0.2,\n",
    "#             patience=7,\n",
    "#             min_lr=1e-4/ 10000,\n",
    "#         ),\n",
    "    ],\n",
    "    use_multiprocessing=True,\n",
    "    workers=4,\n",
    "    # class_weight=hyperparams[\"loss_weights\"],\n",
    ")\n",
    "metrics.append(history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(metrics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics.to_csv(\n",
    "        os.path.join(model_path,  \"losses.csv\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax  = df_metrics.plot()\n",
    "fig = ax.get_figure()\n",
    "\n",
    "\n",
    "fig.savefig(\n",
    "    os.path.join(model_path, \"losses.png\"), dpi=150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(model_path, \"model.json\"), \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test  model and save predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Define\n",
    "model_path = 'logs/2020-10-27_17-13-35'\n",
    "\n",
    "# test_set_name = 'pins-test__detectionDataset'  # 'DB3_testset'\n",
    "test_set_name = 'DB3_testset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(test_set_name == 'DB3_testset'):\n",
    "    test_dir = os.path.join(config.DATA_DIR_GENERAL, \"DB3_test_pins_task\")\n",
    "\n",
    "    test_files = glob.glob(os.path.join(test_dir, img_folder, '*.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join(test_dir,  img_folder)\n",
    "storage_result_masks = os.path.join(model_path, \"results\", test_set_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_samples = len(test_files)\n",
    "testGene = testGenerator(test_path, num_image=test_samples)#\"data/membrane/test\")\n",
    "# model = unet()\n",
    "# model.load_weights(\"unet_membrane.hdf5\")\n",
    "model = nn_utils.load_model(model_path)\n",
    "\n",
    "results = model.predict_generator(testGene,test_samples,verbose=1)\n",
    "\n",
    "\n",
    "if not os.path.exists(storage_result_masks):\n",
    "    os.makedirs(storage_result_masks)\n",
    "\n",
    "# saveResult(\"data/membrane/test\",results)\n",
    "saveResult(storage_result_masks,results, test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = os.path.join(test_dir,  label_folder)\n",
    "\n",
    "testGene = testGenerator(test_path, labels_path=labels_path, num_image=test_samples)#\"data/membrane/test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(test_samples):\n",
    "    img, mks = next(testGene)\n",
    "    \n",
    "    x_test.append(img[0,:,:,:])\n",
    "    y_test.append(mks[0,:,:,:])\n",
    "    \n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet()\n",
    "model_to_chose = nn_utils.select_model(model_path)\n",
    "# load weights into new model\n",
    "model.load_weights(os.path.join(model_path, model_to_chose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=20)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mks[0,:,:,0] , cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(mks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# results easy visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorage_vis_dir =  os.path.join(model_path,\"res_visualization\", test_set_name)\n",
    "\n",
    "if not os.path.exists(sorage_vis_dir):\n",
    "    os.makedirs(sorage_vis_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "\n",
    "all_files = glob.glob(test_path + \"/*.png\")\n",
    "\n",
    "sample_test_files = random.sample(all_files, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (test_set_name == 'DB3_testset'):\n",
    "    \n",
    "    for file_name in sample_test_files:\n",
    "        sample_name =  file_name.split('/')[-1]\n",
    "\n",
    "        label_path = labels_path + '/' + sample_name\n",
    "        pred_path = storage_result_masks + '/' + sample_name\n",
    "\n",
    "\n",
    "        img = cv2.imread(file_name, 0)\n",
    "        label = cv2.imread(label_path, 0)\n",
    "        pred = cv2.imread(pred_path, 0)\n",
    "\n",
    "        img = exposure.adjust_gamma(img, config.GAMMA)\n",
    "\n",
    "\n",
    "        #plotting\n",
    "        fig,ax = plt.subplots(1, 3, figsize=(10,5))\n",
    "        ax[0].imshow(img, cmap='gray')\n",
    "        ax[1].imshow(label, cmap='gray')\n",
    "        ax[2].imshow(pred, cmap='gray')\n",
    "        ax[0].set(title=\"Original Img\")\n",
    "        ax[1].set(title=\"GT\")\n",
    "        ax[2].set(title=\"Prediciton\")\n",
    "\n",
    "        fig.tight_layout() # if needed\n",
    "        fig.savefig( os.path.join(sorage_vis_dir, sample_name), dpi=100)\n",
    "\n",
    "\n",
    "        plt.clf() \n",
    "        plt.close('all')   \n",
    "        plt.close(fig)\n",
    "else:\n",
    "    #no segmentation GT for DB3\n",
    "    for file_name in sample_test_files:\n",
    "        sample_name =  file_name.split('/')[-1]\n",
    "\n",
    "        pred_path = storage_result_masks + '/' + sample_name\n",
    "\n",
    "\n",
    "        img = cv2.imread(file_name, 0)\n",
    "        pred = cv2.imread(pred_path, 0)\n",
    "\n",
    "        img = exposure.adjust_gamma(img, config.GAMMA)\n",
    "\n",
    "\n",
    "        #plotting\n",
    "        fig,ax = plt.subplots(1, 2, figsize=(10,5))\n",
    "        ax[0].imshow(img, cmap='gray')\n",
    "        ax[1].imshow(pred, cmap='gray')\n",
    "        ax[0].set(title=\"Original Img\")\n",
    "        ax[1].set(title=\"Prediciton\")\n",
    "\n",
    "        fig.tight_layout() # if needed\n",
    "        fig.savefig( os.path.join(sorage_vis_dir, sample_name), dpi=100)\n",
    "\n",
    "\n",
    "        plt.clf() \n",
    "        plt.close('all')   \n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
